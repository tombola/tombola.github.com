---
layout: post
published: false
category: geekery
tagline: new interfaces
tags: "interfaces, usability, accessibility"
---

Eye tracking is on the way.

I know, we've had it for years, but its been tucked away in usability labs, and it cost a bomb.

I've been looking around to see if eye tracking might be within reach, cheap and off the shelf for usability testing. It doesn't seem to be quite there for my purposes, but we are tantalisingly close.

First you had to hold your head still.

Then you had to wear tiny cameras on a hat or glasses.

Then you could use infra red cameras, but the hardware was expensive.

Now it looks like we might be able to buy a compact, simple **cheap** [device](https://theeyetribe.com/) to handle all the complicated stuff and develop all sorts of clever things over the top of it. This opens  up the field to experimentation, in the same way as the kinect did for full body sensing.

The release of an sdk and developer kit prior to a user-ready product seems to be an encouraging trend. [Leap Motion](https://www.leapmotion.com/) did a similar thing for hand gestures for example.